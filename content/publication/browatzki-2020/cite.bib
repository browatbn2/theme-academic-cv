@article{Browatzki2020,
 abstract = {We propose an encoder-decoder framework for the segmentation of blood vessels in retinal images that relies on the extraction of large-scale patches at multiple image-scales during training. Experiments on three fundus image datasets demonstrate that this approach achieves state-of-the-art results and can be implemented using a simple and efficient fully-convolutional network with a parameter count of less than 0.8M. Furthermore, we show that this framework - called VLight - avoids overfitting to specific training images and generalizes well across different datasets, which makes it highly suitable for real-world applications where robustness, accuracy as well as low inference time on high-resolution fundus images is required.},
 author = {Browatzki, Björn and Lies, Jörn Philipp and Wallraven, Christian},
 doi = {10.1007/978-3-030-63419-3_5},
 file = {:home/browatbn/Dropbox/Papers/browatzki_OMIA_2020.pdf:pdf},
 isbn = {9783030634186},
 issn = {16113349},
 journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
 keywords = {Fundus image,Residual networks,Retinal vessel detection,Semantic segmentation},
 pages = {42--52},
 title = {Encoder-Decoder Networks for Retinal Vessel Segmentation Using Large Multi-scale Patches},
 volume = {12069 LNCS},
 year = {2020}
}
